{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix(df, subset=[], details=\"All Features\"):\n",
    "    \"\"\"Plots a correlation matrix of all the features. Can specify subset of features if desired\"\"\"\n",
    "\n",
    "    if len(subset)>0:\n",
    "        df = df[subset]\n",
    "        \n",
    "    corr = df.corr()\n",
    "    #print(\"First 3 correlations: \"+str(corr.iloc[0,0:3]))\n",
    "    #cmap = sn.diverging_palette(255, 133, l=60, n=7, center=\"dark\")\n",
    "    \n",
    "    # The values number here ar just for \"nice\" scaling\n",
    "    xx=(df.shape[1]/3,(df.shape[1]/3)*.85 )\n",
    "    fig=plt.figure(figsize=xx)\n",
    "    ax = sn.heatmap(corr,cmap='RdBu_r',vmin=-1,vmax=1)\n",
    "\n",
    "    ax.set_title(\"Correlation for \"+details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_target_to_end(df,target_label):\n",
    "    \n",
    "    \"\"\"Moves the target colums to the end of the DataFrame for easier book-keeping\n",
    "    and correlation matrix display\"\"\"\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    p = cols.index(target_label)\n",
    "    cols_new=cols[0:p]\n",
    "    cols_new = cols_new + cols[p+1:]\n",
    "    cols_new.append(cols[p])\n",
    "    \n",
    "    df=df[cols_new]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_features(df,target_label,n_features=10,exclude_labels=None):\n",
    "    \"\"\" Select the n features most highly correlated with the specified \n",
    "    target aviables. NOTE: should only run this with df that has the target \n",
    "    still embedded; will return erroneous result if used e.g. with x\"\"\"\n",
    "    \n",
    "    # Set upper limit on number of features that can be returned\n",
    "    if exclude_labels is not None:\n",
    "        length_constraint = len(df.columns)-1-len(exclude_labels)\n",
    "    else:\n",
    "        length_constraint = len(df.columns)-1\n",
    "    \n",
    "    # if n_features is too high, cap it and print a warning\n",
    "    if n_features>length_constraint:\n",
    "        print(\"warning: number of features cannot exceed \"+str(length_constraint)+\n",
    "              \"\\nSelecting \"+str(length_constraint)+\"features.\")\n",
    "        n_features = length_constraint\n",
    "    \n",
    "    df=move_target_to_end(df,target_label)\n",
    "    \n",
    "    corr_vals_sorted=abs(df.corr()).iloc[-1].sort_values(ascending=False)\n",
    "    #print(exclude_labels)\n",
    "    high_corr_feat = list(corr_vals_sorted.index[1:n_features+1])\n",
    "    \n",
    "    # count the excluded labels\n",
    "    c=0\n",
    "    if exclude_labels is not None:\n",
    "        for li in range(len(exclude_labels)):\n",
    "            if exclude_labels[li] in high_corr_feat:\n",
    "                high_corr_feat.remove(exclude_labels[li]) \n",
    "                c+=1\n",
    "                high_corr_feat.append(corr_vals_sorted.index[n_features+c])\n",
    "            \n",
    "    #print(high_corr_feat)\n",
    "    return high_corr_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(x,y, features=[],do_scale=True, show_cm=False,normTF=True):\n",
    "    \n",
    "    if len(features)>0:\n",
    "        #print(len(features)>0)\n",
    "        x=x[features]\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.2,random_state=3)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    if do_scale:\n",
    "        regressor = Pipeline(steps = [('scaler',StandardScaler()),('model',model)])\n",
    "    else:\n",
    "        regressor = Pipeline(steps = [('model',model)])\n",
    "        \n",
    "    regressor.fit(x_train,y_train)\n",
    "    y_predict = regressor.predict(x_val)\n",
    "    \n",
    "    scores = cross_val_score(regressor, x, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(\"RMSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    # Display some random validation vs predicted y pairs\n",
    "    rand_samp = list(np.random.choice(range(len(y_val)),10,replace=False))\n",
    "    y_top = np.array(y_val.iloc[rand_samp])\n",
    "    # Rounding the predicted values for display purposes\n",
    "    yp_top = np.array(y_predict[rand_samp]).round()\n",
    "    \n",
    "    Y = np.array([y_top,yp_top]).T\n",
    "    print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def dtree_reg(x,y, features=[],do_scale=True, show_cm=False,normTF=True):\n",
    "    \n",
    "    if len(features)>0:\n",
    "        #print(len(features)>0)\n",
    "        x=x[features]\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.2,random_state=3)\n",
    "    \n",
    "    model = DecisionTreeRegressor(random_state=3)\n",
    "    if do_scale:\n",
    "        regressor = Pipeline(steps = [('scaler',StandardScaler()),('model',model)])\n",
    "    else:\n",
    "        regressor = Pipeline(steps = [('model',model)])\n",
    "        \n",
    "    regressor.fit(x_train,y_train)\n",
    "    y_predict = regressor.predict(x_val)\n",
    "    \n",
    "    scores = cross_val_score(regressor, x, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(\"RMSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    # Display some random validation vs predicted y pairs\n",
    "    rand_samp = list(np.random.choice(range(len(y_val)),10,replace=False))\n",
    "    y_top = np.array(y_val.iloc[rand_samp])\n",
    "    # Rounding the predicted values for display purposes\n",
    "    yp_top = np.array(y_predict[rand_samp]).round()\n",
    "    \n",
    "    Y = np.array([y_top,yp_top]).T\n",
    "    print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def randfor_reg(x,y, features=[],do_scale=True, show_cm=False,normTF=True):\n",
    "    \n",
    "    if len(features)>0:\n",
    "        #print(len(features)>0)\n",
    "        x=x[features]\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.2,random_state=3)\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=3, n_estimators=100)\n",
    "    if do_scale:\n",
    "        regressor = Pipeline(steps = [('scaler',StandardScaler()),('model',model)])\n",
    "    else:\n",
    "        regressor = Pipeline(steps = [('model',model)])\n",
    "        \n",
    "    regressor.fit(x_train,y_train)\n",
    "    y_predict = regressor.predict(x_val)\n",
    "    \n",
    "    scores = cross_val_score(regressor, x, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(\"RMSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    # Display some random validation vs predicted y pairs\n",
    "    rand_samp = list(np.random.choice(range(len(y_val)),10,replace=False))\n",
    "    y_top = np.array(y_val.iloc[rand_samp])\n",
    "    # Rounding the predicted values for display purposes\n",
    "    yp_top = np.array(y_predict[rand_samp]).round()\n",
    "    \n",
    "    Y = np.array([y_top,yp_top]).T\n",
    "    print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def print_gridsearch_results(clf,x_valid, y_valid):\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    y_pred = clf.predict(x_valid)\n",
    "    print(classification_report(y_valid, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
